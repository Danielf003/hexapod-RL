{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "jSnUMNLC8WMK",
      "metadata": {
        "id": "jSnUMNLC8WMK"
      },
      "source": [
        "---\n",
        "\n",
        "Швецов Д.А. ИСУ: 285659\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7NIL8rtuYIey",
      "metadata": {
        "id": "7NIL8rtuYIey"
      },
      "source": [
        "#Лаб. 7. Proximal policy optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p3T78LMsYR1E",
      "metadata": {
        "id": "p3T78LMsYR1E"
      },
      "source": [
        "##Сетап"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7-3PzyNmeOZk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-3PzyNmeOZk",
        "outputId": "3f5f1093-56d6-4199-887a-78d7b9e448eb"
      },
      "outputs": [],
      "source": [
        "# !sudo apt-get update\n",
        "# !sudo apt-get install -y xvfb python3-opengl\n",
        "# !pip install pyvirtualdisplay\n",
        "# !pip install gym[classic_control]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "extended-morocco",
      "metadata": {
        "id": "extended-morocco"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from IPython import display\n",
        "# from pyvirtualdisplay import Display\n",
        "# d = Display(visible=0, size=(400, 300))\n",
        "# d.start()\n",
        "\n",
        "def show_state(env, episode=0, step=0, info=\"\"):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    plt.imshow(env.render())#mode='rgb_array'))\n",
        "    plt.title(\"%s | Eposide: %d | Step: %d %s\" % ('Cart-pole-v1', episode, step, info))\n",
        "    plt.axis('off')\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0orEW4pfmQuF",
      "metadata": {
        "id": "0orEW4pfmQuF"
      },
      "outputs": [],
      "source": [
        "# import copy\n",
        "import torch\n",
        "from torch import distributions\n",
        "# from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# import random\n",
        "# import math\n",
        "# import torchvision.transforms as T\n",
        "import numpy as np\n",
        "# import time\n",
        "# import gym, math\n",
        "import gymnasium as gym\n",
        "from scipy.signal import lfilter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s0XIDek4YXuA",
      "metadata": {
        "id": "s0XIDek4YXuA"
      },
      "source": [
        "##Классы и функции"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LYwKEKvwbCqE",
      "metadata": {
        "id": "LYwKEKvwbCqE"
      },
      "source": [
        "Честно взято отсюда: https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/ppo/core.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aASGZqGFZA1V",
      "metadata": {
        "id": "aASGZqGFZA1V"
      },
      "outputs": [],
      "source": [
        "# Чтобы не прописывать все слои сети руками\n",
        "def mlp(sizes, activation, output_activation=torch.nn.Identity):\n",
        "    layers = []\n",
        "    for j in range(len(sizes)-1):\n",
        "        act = activation if j < len(sizes)-2 else output_activation\n",
        "        layers += [torch.nn.Linear(sizes[j], sizes[j+1]), act()]\n",
        "    return torch.nn.Sequential(*layers)\n",
        "\n",
        "# Для подсчета массива ожидаемых суммарных\n",
        "# вознаграждений с дисконтированием по массиву наград\n",
        "def discount_cumsum(x, discount):\n",
        "  return lfilter(\n",
        "      b=[1],\n",
        "      a=[1, float(-discount)],\n",
        "      x=x[::-1],\n",
        "      axis=0)[::-1]\n",
        "\n",
        "# # Агент, который еще только учится\n",
        "# class MLPCategoricalActor(torch.nn.Module):\n",
        "#     def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
        "#         super().__init__()\n",
        "#         self.logits_net = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
        "\n",
        "#     def get_policy(self, obs):\n",
        "#         logits = self.logits_net(obs)\n",
        "#         return distributions.Categorical(logits=logits)\n",
        "\n",
        "#     def _log_prob_from_distribution(self, pi, act):\n",
        "#         return pi.log_prob(act)\n",
        "\n",
        "#     def forward(self, obs, act=None):\n",
        "#         # Produce action distributions for given observations, and\n",
        "#         # optionally compute the log likelihood of given actions under\n",
        "#         # those distributions.\n",
        "#         pi = self.get_policy(obs)\n",
        "#         logp_a = None\n",
        "#         if act is not None:\n",
        "#             logp_a = self._log_prob_from_distribution(pi, act)\n",
        "#         return pi, logp_a\n",
        "\n",
        "# Агент, который еще только учится\n",
        "class MLPGaussianActor(torch.nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, hidden_sizes, activation):\n",
        "        super().__init__()\n",
        "        log_std = -0.5 * np.ones(act_dim, dtype=np.float32)\n",
        "        self.log_std = torch.nn.Parameter(torch.as_tensor(log_std))\n",
        "        self.mu_net = mlp([obs_dim] + list(hidden_sizes) + [act_dim], activation)\n",
        "\n",
        "    def get_policy(self, obs):\n",
        "        mu = self.mu_net(obs)\n",
        "        std = torch.exp(self.log_std)\n",
        "        return distributions.Normal(mu, std)\n",
        "\n",
        "    def _log_prob_from_distribution(self, pi, act):\n",
        "        return pi.log_prob(act).sum(axis=-1)    # Last axis sum needed for Torch Normal distribution\n",
        "    \n",
        "    def forward(self, obs, act=None):\n",
        "        # Produce action distributions for given observations, and\n",
        "        # optionally compute the log likelihood of given actions under\n",
        "        # those distributions.\n",
        "        pi = self.get_policy(obs)\n",
        "        logp_a = None\n",
        "        if act is not None:\n",
        "            logp_a = self._log_prob_from_distribution(pi, act)\n",
        "        return pi, logp_a\n",
        "\n",
        "# Начинающий оценщик V-функции\n",
        "class MLPCritic(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, obs_dim, hidden_sizes, activation):\n",
        "        super().__init__()\n",
        "        self.v_net = mlp([obs_dim] + list(hidden_sizes) + [1], activation)\n",
        "\n",
        "    def forward(self, obs):\n",
        "        return torch.squeeze(self.v_net(obs), -1) # Critical to ensure v has right shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a_SZ6ZjsqxJs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_SZ6ZjsqxJs",
        "outputId": "dc1c47ac-67e1-4db1-eb64-80d8db08bf01"
      },
      "outputs": [],
      "source": [
        "from gymnasium.spaces import Box, Discrete\n",
        "\n",
        "class PPOac(torch.nn.Module):\n",
        "    def __init__(self, observation_space, action_space, hidden_dim=12, pi_lr=3e-4, vf_lr=1e-3, train_pi_iters=5, train_v_iters=5, target_kl=0.01, clip_ratio=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        activation = torch.nn.Tanh\n",
        "        # activation = torch.nn.LeakyReLU()\n",
        "        hidden_sizes = [hidden_dim] * 1\n",
        "\n",
        "        if isinstance(action_space, Box):\n",
        "            self.pi = MLPGaussianActor(observation_space.shape[0], action_space.shape[0], hidden_sizes, activation)\n",
        "        elif isinstance(action_space, Discrete):\n",
        "            # self.pi = MLPCategoricalActor(state_dim, action_dim, hidden_sizes, activation)\n",
        "            raise ValueError('Are you sure you want discrete action space?')\n",
        "        else:\n",
        "            raise ValueError('What the heck is this action space?')\n",
        "\n",
        "        # build value function\n",
        "        self.v  = MLPCritic(observation_space.shape[0], hidden_sizes, activation)\n",
        "\n",
        "        self.pi_optimizer = torch.optim.Adam(self.pi.parameters(), lr=pi_lr)\n",
        "        self.vf_optimizer = torch.optim.Adam(self.v.parameters(), lr=vf_lr)\n",
        "        self.train_pi_iters = train_pi_iters\n",
        "        self.train_v_iters = train_v_iters\n",
        "        self.target_kl = target_kl\n",
        "        self.clip_ratio = clip_ratio\n",
        "\n",
        "    def get_action(self, state):\n",
        "        with torch.no_grad():\n",
        "            obs = torch.as_tensor(state, dtype=torch.float32)\n",
        "            pi = self.pi.get_policy(obs)\n",
        "            a = pi.sample()\n",
        "            logp_a = self.pi._log_prob_from_distribution(pi, a)\n",
        "            v = self.v(obs)\n",
        "        return a.numpy(), v.numpy(), logp_a.numpy()\n",
        "\n",
        "    # def act(self, obs):\n",
        "        #     return self.step(obs)[0]\n",
        "\n",
        "    # Set up function for computing PPO policy loss\n",
        "    def compute_loss_pi(self, obs, act, adv, logp_old):\n",
        "        # obs, act, adv, logp_old = data['obs'], data['act'], data['adv'], data['logp']\n",
        "\n",
        "        # Policy loss\n",
        "        pi, logp = self.pi(obs, act)\n",
        "        ratio = torch.exp(logp - logp_old)\n",
        "        clip_adv = torch.clamp(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * adv\n",
        "        loss_pi = -(torch.min(ratio * adv, clip_adv)).mean()\n",
        "\n",
        "        # # Useful extra info\n",
        "        # approx_kl = (logp_old - logp).mean().item()\n",
        "        # ent = pi.entropy().mean().item()\n",
        "        # clipped = ratio.gt(1 + clip_ratio) | ratio.lt(1 - clip_ratio)\n",
        "        # clipfrac = torch.as_tensor(clipped, dtype=torch.float32).mean().item()\n",
        "        # pi_info = dict(kl=approx_kl, ent=ent, cf=clipfrac)\n",
        "\n",
        "        approx_kl = (logp_old - logp).mean().item()\n",
        "        pi_info = dict(kl=approx_kl)\n",
        "\n",
        "        return loss_pi, pi_info\n",
        "\n",
        "    # Set up function for computing value loss\n",
        "    def compute_loss_v(self, obs, ret):\n",
        "        # obs, ret = data['obs'], data['ret']\n",
        "        return ((self.v(obs) - ret) ** 2).mean()\n",
        "\n",
        "    def update(self, obs, batch_actions, adv, logp_old, ret):\n",
        "        # data = buf.get()\n",
        "        obs = torch.as_tensor(obs, dtype=torch.float32)\n",
        "        act = torch.as_tensor(batch_actions, dtype=torch.float32)\n",
        "        # torch.FloatTensor(\n",
        "        adv = torch.as_tensor(adv, dtype=torch.float32)\n",
        "        logp_old = torch.as_tensor(logp_old, dtype=torch.float32)\n",
        "        ret = torch.as_tensor(ret, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        pi_l_old, pi_info_old = self.compute_loss_pi(obs, act, adv, logp_old)\n",
        "        pi_l_old = pi_l_old.item()\n",
        "        v_l_old = self.compute_loss_v(obs, ret).item()\n",
        "\n",
        "        # Train policy with multiple steps of gradient descent\n",
        "        for i in range(self.train_pi_iters):\n",
        "            self.pi_optimizer.zero_grad()\n",
        "            loss_pi, pi_info = self.compute_loss_pi(obs, act, adv, logp_old)\n",
        "            # kl = mpi_avg(pi_info['kl'])\n",
        "            kl = pi_info['kl']\n",
        "            if kl > 1.5 * self.target_kl:\n",
        "                # logger.log('Early stopping at step %d due to reaching max kl.' % i)\n",
        "                break\n",
        "            loss_pi.backward()\n",
        "            # mpi_avg_grads(ac.pi)  # average grads across MPI processes\n",
        "            self.pi_optimizer.step()\n",
        "\n",
        "        # logger.store(StopIter=i)\n",
        "\n",
        "        # Value function learning\n",
        "        for i in range(self.train_v_iters):\n",
        "            self.vf_optimizer.zero_grad()\n",
        "            loss_v = self.compute_loss_v(obs, ret)\n",
        "            loss_v.backward()\n",
        "            # mpi_avg_grads(ac.v)  # average grads across MPI processes\n",
        "            self.vf_optimizer.step()\n",
        "\n",
        "        # Log changes from update\n",
        "        # kl, ent, cf = pi_info['kl'], pi_info_old['ent'], pi_info['cf']\n",
        "        # logger.store(LossPi=pi_l_old, LossV=v_l_old,\n",
        "        #               KL=kl, Entropy=ent, ClipFrac=cf,\n",
        "        #               DeltaLossPi=(loss_pi.item() - pi_l_old),\n",
        "        #               DeltaLossV=(loss_v.item() - v_l_old))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-89kQd5UYdzE",
      "metadata": {
        "id": "-89kQd5UYdzE"
      },
      "source": [
        "##Обучение\n",
        "Успешно обучилось 4 раза из 7. 3 раза из 7 либо вообще не обучилось, либо есть пара просадок на валидации\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "developmental-lending",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "developmental-lending",
        "outputId": "34ffcb49-e257-4173-ee64-6e9dfa0fbdc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:54: UserWarning: \u001b[33mWARN: A Box action space maximum and minimum values are equal.\u001b[0m\n",
            "  logger.warn(\"A Box action space maximum and minimum values are equal.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SHApes (60,) (24,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Danielf\\AppData\\Local\\Temp\\ipykernel_23280\\1308085951.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
            "  obs = torch.as_tensor(obs, dtype=torch.float32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cpu\"\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "from gymnasium.envs.registration import register\n",
        "register(\n",
        "    id=\"Hexapod-v0\",\n",
        "    entry_point=\"gym_env:HexapodEnv\",\n",
        "    max_episode_steps=1000,\n",
        "    reward_threshold=3800.0,\n",
        ")\n",
        "env = gym.make('Hexapod-v0', render_mode='rgb_array')\n",
        "# env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
        "# env = gym.make('CartPole-v1')\n",
        "print('SHApes',env.observation_space.shape, env.action_space.shape)\n",
        "\n",
        "\n",
        "#PPO\n",
        "\n",
        "# Learning Parameters\n",
        "alpha_pi = 0.01\n",
        "alpha_v = 0.01\n",
        "gsteps_pi = 20\n",
        "gsteps_v = 20\n",
        "gamma=0.99\n",
        "lam = 0.95 # ЭТО lambda ДЛЯ ADVANTAGE\n",
        "\n",
        "# Execution parameters\n",
        "SHOW_ANIMATION = False\n",
        "EPISODES_MAX = 4\n",
        "STEPS_MAX = 1000\n",
        "DESIRED_STEPS = 250\n",
        "\n",
        "# Loggers\n",
        "log_steps_number = np.zeros(EPISODES_MAX)\n",
        "\n",
        "# n_states = 4\n",
        "# n_actions = 2\n",
        "n_hidden = 10\n",
        "\n",
        "agent = PPOac(env.observation_space, env.action_space, n_hidden, alpha_pi, alpha_v, gsteps_pi, gsteps_v)\n",
        "scheduler_pi = StepLR(agent.pi_optimizer, step_size=10, gamma=0.7)\n",
        "scheduler_v = StepLR(agent.vf_optimizer, step_size=10, gamma=0.7)\n",
        "\n",
        "#data storage\n",
        "batch_size = 400\n",
        "\n",
        "batch_states = []\n",
        "batch_actions = []\n",
        "batch_ret = []\n",
        "batch_adv = []\n",
        "batch_logps = []\n",
        "\n",
        "epoch = 0\n",
        "\n",
        "# PPO\n",
        "for i_episode in range(EPISODES_MAX):\n",
        "    episode_states = []\n",
        "    episode_actions = []\n",
        "    episode_rewards = []\n",
        "    # episode_total_return = 0\n",
        "    episode_logps = []\n",
        "    episode_vals = []\n",
        "    episode_ret = []\n",
        "\n",
        "    observation = env.reset()[0]\n",
        "    state = observation\n",
        "\n",
        "    # show results\n",
        "    if (i_episode + 1) % 10 == 0:\n",
        "        plt.figure(1)\n",
        "        plt.clf()\n",
        "        plt.plot([0,i_episode], [495, 495], label=\"threshold\")\n",
        "        plt.plot(range(0,i_episode), log_steps_number[0:i_episode], label=\"solution 1\")\n",
        "        plt.xlabel('episode')\n",
        "        plt.ylabel('episode steps')\n",
        "        plt.legend()\n",
        "        plt.title('alpha_pi={} alpha_v={} epoch={}'.format(scheduler_pi.get_last_lr()[0],scheduler_v.get_last_lr()[0],epoch))\n",
        "        display.clear_output(wait=True)\n",
        "        plt.show()\n",
        "\n",
        "    for t in range(STEPS_MAX):\n",
        "        # if SHOW_ANIMATION or (i_episode > 0.9*EPISODES_MAX and t > 0.95*DESIRED_STEPS):\n",
        "        #     print(i_episode, 0.9*EPISODES_MAX, 0.95*DESIRED_STEPS)\n",
        "        #     # show_state(env.env, i_episode, t)\n",
        "        #     # env.render()\n",
        "        if (i_episode+1)%50 == 0 and i_episode > 0.5*EPISODES_MAX and t > DESIRED_STEPS and i_episode+1 != EPISODES_MAX:\n",
        "            # print(i_episode, 0.9*EPISODES_MAX, 0.95*DESIRED_STEPS)\n",
        "            show_state(env.env, i_episode, t)\n",
        "            # env.render()\n",
        "\n",
        "\n",
        "        action, v, logp = agent.get_action(state)\n",
        "        # print(action,v,logp)\n",
        "        action = action.tolist()\n",
        "        logp = logp.tolist()\n",
        "\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # episode_total_return += reward\n",
        "        episode_states.append(state)\n",
        "        episode_actions.append(action)\n",
        "        episode_rewards.append(reward)\n",
        "        episode_logps.append(logp)\n",
        "        episode_vals.append(v)\n",
        "\n",
        "        state = observation\n",
        "\n",
        "        if done:\n",
        "            log_steps_number[i_episode] = t;\n",
        "\n",
        "            last_val = 0\n",
        "            episode_ended = t == STEPS_MAX - 1\n",
        "            if episode_ended:\n",
        "              _, last_val, _ = agent.get_action(state)\n",
        "            rews = np.append(episode_rewards, last_val)\n",
        "            vals = np.append(episode_vals, last_val)\n",
        "            # the next two lines implement GAE-Lambda advantage calculation\n",
        "            deltas = rews[:-1] + gamma * vals[1:] - vals[:-1]\n",
        "            episode_adv = discount_cumsum(deltas, gamma * lam).tolist()\n",
        "            # the next line computes rewards-to-go, to be targets for the value function\n",
        "            episode_ret = discount_cumsum(rews, gamma)[:-1].tolist()\n",
        "\n",
        "            batch_states += episode_states\n",
        "            batch_actions += episode_actions\n",
        "            batch_logps += episode_logps\n",
        "            batch_adv += episode_adv\n",
        "            batch_ret += episode_ret\n",
        "\n",
        "\n",
        "            if len(batch_states) >= batch_size:\n",
        "              agent.update(batch_states, batch_actions, batch_adv, batch_logps, batch_ret)\n",
        "\n",
        "              epoch += 1\n",
        "              batch_states = []\n",
        "              batch_actions = []\n",
        "              batch_logps = []\n",
        "              batch_adv = []\n",
        "              batch_ret = []\n",
        "\n",
        "              scheduler_pi.step()\n",
        "              scheduler_v.step()\n",
        "\n",
        "            break\n",
        "\n",
        "print(\"done\")\n",
        "path_weights = 'hex.weights'\n",
        "torch.save(agent.state_dict(), path_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fh5hIuNbYnQ3",
      "metadata": {
        "id": "Fh5hIuNbYnQ3"
      },
      "source": [
        "##Проверка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "J-d0kCYc5dsm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "J-d0kCYc5dsm",
        "outputId": "a52e1048-851a-4353-f79b-ce38b15d7b1d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(STEPS_MAX):\n\u001b[0;32m     31\u001b[0m     action, _, _ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(state)\n\u001b[1;32m---> 32\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[0;32m     34\u001b[0m     state \u001b[38;5;241m=\u001b[39m observation\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Soft\\hexapod-RL\\gym_template.py:329\u001b[0m, in \u001b[0;36mHopperEnv8.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    327\u001b[0m x_position_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# ctrl = self.action2control(action)\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_skip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m x_position_after \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    331\u001b[0m x_velocity \u001b[38;5;241m=\u001b[39m (x_position_after \u001b[38;5;241m-\u001b[39m x_position_before) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:205\u001b[0m, in \u001b[0;36mMujocoEnv.do_simulation\u001b[1;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(ctrl)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnu,):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction dimension mismatch. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnu,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39marray(ctrl)\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_mujoco_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_frames\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Soft\\miniconda3\\envs\\hex\\lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:153\u001b[0m, in \u001b[0;36mMujocoEnv._step_mujoco_simulation\u001b[1;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mStep over the MuJoCo simulation.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mctrl[:] \u001b[38;5;241m=\u001b[39m ctrl\n\u001b[1;32m--> 153\u001b[0m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmj_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# As of MuJoCo 2.0, force-related quantities like cacc are not computed\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# unless there's a force sensor in the model.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# See https://github.com/openai/gym/issues/1541\u001b[39;00m\n\u001b[0;32m    158\u001b[0m mujoco\u001b[38;5;241m.\u001b[39mmj_rnePostConstraint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# env = gym.make('CartPole-v1')\n",
        "# env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
        "env = gym.make('Hexapod-v0', render_mode='rgb_array')\n",
        "\n",
        "# Execution parameters\n",
        "SHOW_ANIMATION = False\n",
        "EPISODES_MAX = 300\n",
        "STEPS_MAX = 1000\n",
        "\n",
        "# Loggers\n",
        "log_steps_number = np.zeros(EPISODES_MAX)\n",
        "\n",
        "# PQ\n",
        "for i_episode in range(EPISODES_MAX):\n",
        "    observation = env.reset()[0]\n",
        "    state = observation\n",
        "\n",
        "    # show results\n",
        "    if (i_episode + 1) % 20 == 0:\n",
        "        plt.figure(1)\n",
        "        plt.clf()\n",
        "        plt.plot([0,i_episode], [495, 495], label=\"threshold\")\n",
        "        plt.plot(range(0,i_episode), log_steps_number[0:i_episode], label=\"solution 1\")\n",
        "        plt.xlabel('episode')\n",
        "        plt.ylabel('episode steps')\n",
        "        plt.legend()\n",
        "        display.clear_output(wait=True)\n",
        "        plt.show()\n",
        "\n",
        "    for t in range(STEPS_MAX):\n",
        "        action, _, _ = agent.get_action(state)\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        state = observation\n",
        "\n",
        "        if done:\n",
        "            log_steps_number[i_episode] = t;\n",
        "            break\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e19a903",
      "metadata": {},
      "source": [
        "Загрузка весов обученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bca0018e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Danielf\\AppData\\Local\\Temp\\ipykernel_23280\\1149551841.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_agent.load_state_dict(torch.load(path_weights))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PPOac(\n",
              "  (pi): MLPGaussianActor(\n",
              "    (mu_net): Sequential(\n",
              "      (0): Linear(in_features=60, out_features=10, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=10, out_features=24, bias=True)\n",
              "      (3): Identity()\n",
              "    )\n",
              "  )\n",
              "  (v): MLPCritic(\n",
              "    (v_net): Sequential(\n",
              "      (0): Linear(in_features=60, out_features=10, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=10, out_features=1, bias=True)\n",
              "      (3): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Later to restore:\n",
        "new_agent = PPOac(env.observation_space, env.action_space, n_hidden)\n",
        "new_agent.load_state_dict(torch.load(path_weights))\n",
        "new_agent.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dd8d163b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('Hexapod-v0', render_mode='rgb_array')\n",
        "\n",
        "# Execution parameters\n",
        "SHOW_ANIMATION = False\n",
        "EPISODES_MAX = 40\n",
        "STEPS_MAX = 1000\n",
        "\n",
        "# Loggers\n",
        "log_steps_number = np.zeros(EPISODES_MAX)\n",
        "\n",
        "# PQ\n",
        "for i_episode in range(EPISODES_MAX):\n",
        "    observation = env.reset()[0]\n",
        "    state = observation\n",
        "\n",
        "    # show results\n",
        "    if (i_episode + 1) % 20 == 0:\n",
        "        plt.figure(1)\n",
        "        plt.clf()\n",
        "        plt.plot([0,i_episode], [495, 495], label=\"threshold\")\n",
        "        plt.plot(range(0,i_episode), log_steps_number[0:i_episode], label=\"solution 1\")\n",
        "        plt.xlabel('episode')\n",
        "        plt.ylabel('episode steps')\n",
        "        plt.legend()\n",
        "        display.clear_output(wait=True)\n",
        "        plt.show()\n",
        "\n",
        "    for t in range(STEPS_MAX):\n",
        "        action, _, _ = new_agent.get_action(state)\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        state = observation\n",
        "\n",
        "        if done:\n",
        "            log_steps_number[i_episode] = t;\n",
        "            break\n",
        "\n",
        "print(\"done\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "p3T78LMsYR1E"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hex",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
